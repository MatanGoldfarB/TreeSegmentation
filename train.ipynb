{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"elapsed":2612,"status":"ok","timestamp":1727426841684,"user":{"displayName":"matan goldfarb","userId":"06617319432633985560"},"user_tz":-180},"id":"Eu8GAGqgLEVl","outputId":"e8cfcd1d-14d7-405a-df95-5b1a6d1e9b63"},"outputs":[],"source":["!pip install  ultralytics"]},{"cell_type":"markdown","metadata":{"id":"xoL1c5e9uFwO"},"source":["##Prepare"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2105,"status":"ok","timestamp":1727426844248,"user":{"displayName":"matan goldfarb","userId":"06617319432633985560"},"user_tz":-180},"id":"kUwog8xnDa67","outputId":"190edecc-0986-4b85-f28e-1ddee39293b6"},"outputs":[],"source":["from ultralytics import YOLO\n","import matplotlib.pyplot as plt\n","import cv2\n","import torch\n","# Check if CUDA is available, else fallback to CPU\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"Using device: {device}\")"]},{"cell_type":"markdown","metadata":{"id":"0HAksmZdDpPy"},"source":["##First Training"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":239169,"status":"ok","timestamp":1727373689799,"user":{"displayName":"matan goldfarb","userId":"06617319432633985560"},"user_tz":-180},"id":"8TuUrez8Kz4X","outputId":"8145e6c5-2c56-447d-a537-d6245b0f6e2c"},"outputs":[],"source":["# Load the pre-trained YOLOv8 model\n","model = YOLO(\"yolov8n-seg.pt\")\n","results = model.train(data=\".../config.yaml\",\n","                      epochs=2,\n","                      imgsz=640,\n","                      batch=64,\n","                      device=device,\n","                      project=\".../runs\")\n","del model\n","torch.cuda.empty_cache()"]},{"cell_type":"markdown","metadata":{"id":"wO6bqdpduS3N"},"source":["##Test Model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":460},"executionInfo":{"elapsed":6340,"status":"ok","timestamp":1727426866806,"user":{"displayName":"matan goldfarb","userId":"06617319432633985560"},"user_tz":-180},"id":"WZdYj0vMR0l0","outputId":"cc6c589d-9c20-4159-bdd7-775d02beada3"},"outputs":[],"source":["# Paths\n","modelPath = '.../runs/medium50ep/weights/last.pt'\n","testPath = '.../testImg.jpg'\n","\n","# Load image\n","img = cv2.imread(testPath)\n","\n","# Resize the image to 640x640\n","img_resized = cv2.resize(img, (640, 640))\n","\n","# Normalize the image (convert pixel values to the range [0, 1])\n","img_resized = img_resized / 255.0\n","\n","# Convert the image to a tensor and move it to the device\n","img_tensor = torch.tensor(img_resized).permute(2, 0, 1).unsqueeze(0).float().to(device)  # Shape becomes (1, 3, 640, 640)\n","\n","# Load model and move it to the MPS device\n","model1 = YOLO(modelPath)\n","model1.to(device)  # Move the model to MPS\n","\n","# Run inference\n","results = model1(img_tensor)\n","\n","# Visualize and save the image with bounding boxes and segmentation masks\n","annotated_image = results[0].plot()  # Plots the bounding boxes and masks on the image\n","\n","# Save the annotated image\n","cv2.imwrite('.../output_annotated.png', annotated_image)\n","\n","# Optionally display the image using Matplotlib\n","plt.imshow(cv2.cvtColor(annotated_image, cv2.COLOR_BGR2RGB))\n","plt.axis('off')\n","plt.show()"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyOMn+gxx5mY5N+sUzKrlSCt","collapsed_sections":["0HAksmZdDpPy","Tf9fUXyWuKFz"],"gpuType":"T4","machine_shape":"hm","mount_file_id":"1HrabtHMok0CCc6hGKOQXnSgyp2GONKNW","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
